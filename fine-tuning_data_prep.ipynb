{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "from google.cloud.speech_v1p1beta1 import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to your JSON key file\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = './gc_keys.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Speech-to-Text client\n",
    "client = speech.SpeechClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to your audio file\n",
    "audio_file_uri = 'gs://dsc_tutorial_bucket/ep1_trimmed.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the audio settings for the transcription request\n",
    "audio = types.RecognitionAudio(uri=audio_file_uri)\n",
    "config = types.RecognitionConfig(\n",
    "    encoding=types.RecognitionConfig.AudioEncoding.MP3,\n",
    "    sample_rate_hertz=44100,\n",
    "    language_code='en-US',\n",
    "    enable_speaker_diarization=True,\n",
    "    diarization_speaker_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the transcription request\n",
    "response = client.long_running_recognize(config=config, audio=audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = response.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.results[0].alternatives[0].words[2].speaker_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the transcription results\n",
    "with open('transcription.txt', 'w') as f:\n",
    "    current_speaker = None\n",
    "    for result in r.results:\n",
    "        for word in result.alternatives[0].words:\n",
    "            speaker = 'Speaker {}'.format(word.speaker_tag)\n",
    "            if speaker != current_speaker:\n",
    "                f.write('\\n{}: '.format(speaker))\n",
    "                current_speaker = speaker\n",
    "            f.write('{} '.format(word.word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
